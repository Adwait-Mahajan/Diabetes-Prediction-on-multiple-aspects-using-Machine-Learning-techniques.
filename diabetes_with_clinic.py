# -*- coding: utf-8 -*-
"""Diabetes_with_clinic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OqCKPceXGAQb0vNjJ009IgpvWlDDg5xK
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df = pd.read_csv('/content/drive/MyDrive/Bad_dataset.csv')

df.head()

df.isnull().sum()

df.drop(columns=['ID','No_Pation'], inplace=True)

df.head()

df['Gender'].unique()

df[df['Gender'] == 'f']

df.iloc[991,0] = 'F'

df.iloc[991]

df['Gender'].unique()

df['CLASS'].unique()

df[df['CLASS'] == 'N ']

df.iloc[102,-1] = 'N'

df[df['CLASS'] == 'Y ']

for i in range(996,1000):
  df.iloc[i,-1] = 'Y'

df['CLASS'].unique()

df['CLASS'].value_counts()

sns.countplot(df['CLASS'])

from imblearn.over_sampling import SMOTE

df

df = pd.get_dummies(df, columns=['Gender'], drop_first=True)

# Import label encoder
from sklearn import preprocessing

# label_encoder object knows how to understand word labels.
label_encoder = preprocessing.LabelEncoder()

# Encode labels in column 'species'.
df['CLASS']= label_encoder.fit_transform(df['CLASS'])

df['CLASS'].unique()

sns.countplot(df['CLASS'])

df.head()

df = df.sample(frac=1)

sns.heatmap(df.corr(),cmap='viridis')

df.corr()['CLASS'].sort_values()[:-1].plot(kind='bar')

X = df.drop(columns=['CLASS'], axis=1).values

y = df[['CLASS']].values

from imblearn.over_sampling import SMOTE

Sm = SMOTE()

X,y = Sm.fit_resample(X,y)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42, stratify=y)

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout

model = Sequential()

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.10))

model.add(Dense(32, activation='relu'))

model.add(Dense(3, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=25)

y_train = pd.DataFrame(y_train)

y_train

y_train = pd.get_dummies(y_train, columns=[0])

y_train

y_test = pd.DataFrame(y_test)

y_test = pd.get_dummies(y_test, columns=[0])

y_test

results = model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=300, callbacks=[early_stop], verbose=1)

losses = pd.DataFrame(model.history.history)

losses

losses[]

plt.figure(figsize=(6,8))
losses[['val_loss','loss']].plot()
plt.xlabel('Epochs')
plt.ylabel('Loss')

plt.figure(figsize=(6,8))
losses[['val_accuracy','accuracy']].plot()
plt.xlabel('Epochs')
plt.ylabel('accuracy')

preds = model.predict(X_test)

preds

predictions = np.argmax(preds, axis=1)

predictions

from sklearn.metrics import classification_report, confusion_matrix

predictions = pd.DataFrame(predictions)

predictions

predictions = pd.get_dummies(predictions, columns=[0])

print(classification_report(y_test, predictions))

model.save('Diabetes_Clinic_using_SMOTE.h5')